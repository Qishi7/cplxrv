axis.title.y = element_text(size = 13),
axis.text = element_text(size = 11)
) +
scale_fill_manual(values = c("Re & Im" = re_im_color, "Cplx" = cplx_color)) +
labs(
title = "F1 Score by CI and Type",
fill = "Model Type",
x = "Confidence Interval",
y = "F1 Score"
)
## PA
beta_re_t <- lapply(sim_re_t, function(sim) {
sim$draws[, 1:p]
})
## PA
beta_re_t <- lapply(sim_re_t, function(sim) {
sim$draws$draws[, 1:p]
})
beta_im_t <- lapply(sim_im_t, function(sim) {
sim$draws$draws[, 1:p]
})
## p x n_sim matrix
mse_beta_re_t <- sapply(beta_re_t, function(beta) {
mse_sample(beta, true_beta_re)
})
mse_beta_im_t <- sapply(beta_im_t, function(beta) {
mse_sample(beta, true_beta_im)
})
## find posterior mean
pos_mean_beta_re_t <- sapply(beta_re_t, function(x)
apply(x, MARGIN = 2, FUN = mean))
pos_mean_beta_im_t <- sapply(beta_re_t, function(x)
apply(x, MARGIN = 2, FUN = mean))
mse_beta_mean_re_t <- apply(pos_mean_beta_re_t, 2, mse, true_beta_re)
mse_beta_mean_im_t <- apply(pos_mean_beta_re_t, 2, mse, true_beta_im)
mse_beta_mean_re_1 <- apply(pos_mean_beta_re_t[idx_re, ], 2, mse,
true_beta_re[idx_re])
mse_beta_mean_im_1 <- apply(pos_mean_beta_re_t[idx_im, ], 2, mse,
true_beta_im[idx_im])
mse_beta_mean_re_im_1 <- mse_beta_mean_re_1 + mse_beta_mean_im_1
mse_beta_mean_re_0 <- apply(pos_mean_beta_re_t[!idx_re, ], 2, mse,
true_beta_re[!idx_re])
mse_beta_mean_im_0 <- apply(pos_mean_beta_re_t[!idx_im, ], 2, mse,
true_beta_im[!idx_im])
mse_beta_mean_re_im_0 <- mse_beta_mean_re_0 + mse_beta_mean_im_0
## =========
## Complex t
## =========
beta_ct <- lapply(sim_ct, function(sim) {
sim$draws[, 1:(2*p)]
})
beta_ct <- lapply(sim_ct, function(sim) {
sim$draws$draws[, 1:(2*p)]
})
mse_beta_ct <- sapply(beta_ct, function(beta) {
mse_sample(beta, c(true_beta_re, true_beta_im))
})
pos_mean_beta_ct <- sapply(beta_ct, function(x)
apply(x, MARGIN = 2, FUN = mean))
## use posterior mean as the pt est to compute MSE
mse_beta_mean_ct <- apply(pos_mean_beta_ct, 2,
mse, c(true_beta_re, true_beta_im))
mse_beta_mean_ct_1 <- apply(pos_mean_beta_ct[c(idx_re, idx_im), ], 2, mse,
c(true_beta_re[idx_re], true_beta_im[idx_im]))
mse_beta_mean_ct_0 <- apply(pos_mean_beta_ct[!c(idx_re, idx_im), ], 2, mse,
c(true_beta_re[!idx_re], true_beta_im[!idx_im]))
data_0 <- data.frame(
MSE = c(mse_beta_mean_re_im_0, mse_beta_mean_ct_0),
Model = factor(rep(c("Re & Im", "Cplx"), each = length(mse_beta_mean_re_im_0))),
Group = "0"
)
data_1 <- data.frame(
MSE = c(mse_beta_mean_re_im_1, mse_beta_mean_ct_1),
Model = factor(rep(c("Re & Im", "Cplx"), each = length(mse_beta_mean_re_im_1))),
Group = "1"
)
data <- rbind(data_0, data_1)
ggplot(data, aes(x = MSE, fill = Model)) +
geom_histogram(alpha = 0.7, position = "identity", bins = 40) +
facet_wrap(~ Group, scales = "free_y") +
scale_fill_manual(values = c("Re & Im" = re_im_color, "Cplx" = cplx_color)) +
theme_classic() +
theme(
legend.position = "bottom",
plot.title = element_text(hjust = 0.5, size = 18, face = "bold"),
plot.margin = margin(t = 20, b = 10, l = 8, r = 15),
axis.title.x = element_text(size = 13),
axis.title.y = element_text(size = 13),
axis.text = element_text(size = 11)
) +
labs(
title = "Comparison of MSE Distributions for 0 and 1",
x = "MSE Values",
y = "Frequency",
fill = "Model Type"
)
data <- traindata
n_mcmc <- 3000
mc_cores <- 4
p <- ncol(data[[1]]$X)
print(paste("n =", nrow(data[[1]]$X)))
print(paste("p =", ncol(data[[1]]$X)))
n_sim <- length(data)
print(paste("n_sim =", n_sim))
true_beta_re <- data[[1]]$beta_re
true_beta_im <- data[[1]]$beta_im
idx_re <- true_beta_re != 0
idx_im <- true_beta_im != 0
par_info <- set_par(p = p, prior = "bl", is_cplx = FALSE)
system.time(
sim_re_bl <- parallel::mclapply(data, FUN = function(d) {
gibbs_bl_cpp_full(n_mcmc = n_mcmc, start_lst = par_info$start_lst,
name_par = par_info$name_par,
y = d$y_re, X = d$X)
}, mc.cores = mc_cores)
)
sim_re_bl <- lapply(sim_re_bl, function(data) {
colnames(data$draws) <- par_info$name_par
return(data)
})
system.time(
sim_im_bl <- parallel::mclapply(data, FUN = function(d) {
gibbs_bl_cpp_full(n_mcmc = n_mcmc, start_lst = par_info$start_lst,
name_par = par_info$name_par,
y = d$y_im, X = d$X)
}, mc.cores = mc_cores)
)
sim_im_bl <- lapply(sim_im_bl, function(data) {
colnames(data$draws) <- par_info$name_par
return(data)
})
par_info <- set_par(p = p, prior = "bl", is_cplx = TRUE)
system.time(
sim_cbl <- parallel::mclapply(data, FUN = function(d) {
gibbs_cbl_cpp_full(n_mcmc = n_mcmc, par_info$start_lst,
name_par = par_info$name_par,
y = c(d$y_re, d$y_im),
X = as.matrix(Matrix::bdiag(d$X, d$X)))
}, mc.cores = mc_cores)
)
sim_cbl <- lapply(sim_cbl, function(data) {
colnames(data$draws) <- par_info$name_par
return(data)
})
par_info <- set_par(p = p, prior = "t", is_cplx = FALSE)
system.time(
sim_re_t <- parallel::mclapply(data, FUN = function(d) {
gibbs_t_cpp_full(n_mcmc = n_mcmc, start_lst = par_info$start_lst,
name_par = par_info$name_par,
y = d$y_re, X = d$X)
}, mc.cores = mc_cores)
)
sim_re_t <- lapply(sim_re_t, function(data) {
colnames(data$draws$draws) <- par_info$name_par
return(data)
})
system.time(
sim_im_t <- parallel::mclapply(data, FUN = function(d) {
gibbs_t_cpp_full(n_mcmc = n_mcmc, start_lst = par_info$start_lst,
name_par = par_info$name_par,
y = d$y_im, X = d$X)
}, mc.cores = mc_cores)
)
sim_im_t <- lapply(sim_im_t, function(data) {
colnames(data$draws$draws) <- par_info$name_par
return(data)
})
par_info <- set_par(p = p, prior = "t", is_cplx = TRUE)
system.time(
sim_ct <- parallel::mclapply(data, FUN = function(d) {
gibbs_ct_cpp_full(n_mcmc = n_mcmc, par_info$start_lst,
name_par = par_info$name_par,
y = c(d$y_re, d$y_im),
X = as.matrix(Matrix::bdiag(d$X, d$X)))
}, mc.cores = mc_cores)
)
par_info <- set_par(p = p, prior = "gdp", is_cplx = FALSE)
system.time(
sim_re_gdp <- parallel::mclapply(data, FUN = function(d) {
gibbs_gdp_cpp_full(n_mcmc = n_mcmc, start_lst = par_info$start_lst,
name_par = par_info$name_par,
y = d$y_re, X = d$X)
}, mc.cores = mc_cores)
)
sim_re_gdp <- lapply(sim_re_gdp, function(data) {
colnames(data$draws$draws) <- par_info$name_par
return(data)
})
system.time(
sim_im_gdp <- parallel::mclapply(data, FUN = function(d) {
gibbs_gdp_cpp_full(n_mcmc = n_mcmc, par_info$start_lst,
name_par = par_info$name_par,
y = d$y_im, X = d$X)
}, mc.cores = mc_cores)
)
sim_im_gdp <- lapply(sim_im_gdp, function(data) {
colnames(data$draws$draws) <- par_info$name_par
return(data)
})
par_info <- set_par(p = p, prior = "gdp", is_cplx = TRUE)
system.time(
sim_cgdp <- parallel::mclapply(data, FUN = function(d) {
gibbs_cgdp_cpp_full(n_mcmc = n_mcmc, par_info$start_lst,
name_par = par_info$name_par,
y = c(d$y_re, d$y_im),
X = as.matrix(Matrix::bdiag(d$X, d$X)))
}, mc.cores = mc_cores)
)
sim_cgdp <- lapply(sim_cgdp, function(data) {
colnames(data$draws) <- par_info$name_par
return(data)
})
library(GIGrvg)
install.packages("GIGrvg")
library(GIGrvg)
library(mvtnorm)
library(MASS)
library(splines)
library(fields)
install.packages("fields")
library(GIGrvg)
library(mvtnorm)
library(MASS)
library(splines)
library(fields)
spatial_full_2d <- function(y, X, coords_x, coords_y, n_basis_x = 8, n_basis_y = 8,
n_iter = 5000, burn_in = 1000, a = 1, b = 10,
a_sigma = 0.5, b_sigma = 0.5,
lambda0 = 30, lambda1 = 1,
zeta0 = 0.1, zeta1 = 50) {
# Create tensor product basis functions
Bx <- ns(coords_x, df = n_basis_x)
By <- ns(coords_y, df = n_basis_y)
B <- tensor.prod.model.matrix(Bx, By)
n_basis <- n_basis_x * n_basis_y
# Extend X to create Z (design matrix)
p <- ncol(X)
n <- nrow(X)
Z <- matrix(0, n, p * n_basis)
for (j in 1:p) {
Z[, ((j - 1) * n_basis + 1):(j * n_basis)] <- X[, j] * B
}
pH <- ncol(Z)
# Initialize parameters
sigma2 <- 1.0
zeta1 <- zeta1
zeta0 <- zeta0
theta <- 0.5
gamma <- rbinom(p, 1, theta)  # Initialize gamma with Bernoulli(theta)
eta <- matrix(0, nrow = p * n_basis, ncol = 1)
# Storage for results
samples <- list(
zeta0 = numeric(),
zeta1 = numeric(),
sigma2 = numeric(),
theta = numeric(),
gamma = matrix(0, nrow = p, ncol = n_iter - burn_in),
eta = matrix(0, nrow = p * n_basis, ncol = n_iter - burn_in)  # Store eta samples
)
for (iter in 1:n_iter) {
# Update eta
M_inv <- diag(p * n_basis)
for (j in 1:p) {
start_col <- (j - 1) * n_basis + 1
end_col <- j * n_basis
if (gamma[j] == 1) {
M_inv[start_col:end_col, start_col:end_col] <- (1 / zeta1) * diag(n_basis)
} else {
M_inv[start_col:end_col, start_col:end_col] <- (1 / zeta0) * diag(n_basis)
}
}
K <- solve(M_inv + (t(Z) %*% Z) / sigma2)
mean_eta <- K %*% (t(Z) %*% y) / sigma2  # Mean of eta
eta <- MASS::mvrnorm(1, mu = mean_eta, Sigma = K)  # Sample eta from multivariate normal
# Update sigma2
residuals <- y - Z %*% eta
a_sigma_post <- n / 2 + a_sigma
b_sigma_post <- sum(residuals^2) / 2 + b_sigma
sigma2 <- 1 / rgamma(1, shape = a_sigma_post, rate = b_sigma_post)  # Sample sigma2 from inverse gamma
# Update theta
a_theta_post <- a + sum(gamma)
b_theta_post <- b + p - sum(gamma)
theta <- rbeta(1, a_theta_post, b_theta_post)  # Sample theta from beta distribution
# Update zeta1 (using GIG distribution)
sum_eta_squared <- 0
for (j in which(gamma == 1)) {
start_col <- (j - 1) * n_basis + 1
end_col <- j * n_basis
sum_eta_squared <- sum_eta_squared + sum(eta[start_col:end_col]^2)
}
zeta1 <- GIGrvg::rgig(1, lambda = (n_basis + 1 - sum(gamma) * n_basis) / 2,
chi = sum_eta_squared, psi = lambda1^2)
# Update zeta0 (using GIG distribution)
sum_eta_squared <- 0
for (j in which(gamma == 0)) {
start_col <- (j - 1) * n_basis + 1
end_col <- j * n_basis
sum_eta_squared <- sum_eta_squared + sum(eta[start_col:end_col]^2)
}
zeta0 <- GIGrvg::rgig(1, lambda = (n_basis + 1 - (p - sum(gamma)) * n_basis) / 2,
chi = sum_eta_squared, psi = lambda0^2)
# Update gamma
for (j in 1:p) {
start_col <- (j - 1) * n_basis + 1
end_col <- j * n_basis
eta_j <- eta[start_col:end_col]
# Compute probabilities for spike and slab
prob_slab <- theta * mvtnorm::dmvnorm(eta_j, mean = rep(0, n_basis), sigma = zeta1 * diag(n_basis))
prob_spike <- (1 - theta) * mvtnorm::dmvnorm(eta_j, mean = rep(0, n_basis), sigma = zeta0 * diag(n_basis))
# Calculate phi_j
phi_j <- prob_slab / (prob_slab + prob_spike)
# Sample gamma_j using phi_j
gamma[j] <- rbinom(1, 1, phi_j)
}
if (iter %% 100 == 0) {
selected_vars <- which(gamma == 1)
cat("Iteration:", iter, "\n")
cat("  theta:", theta, "\n")
cat("  sigma2:", sigma2, "\n")
cat("  zeta1:", zeta1, "\n")
cat("  zeta0:", zeta0, "\n")
cat("  Selected variables:", selected_vars, "\n")
cat("\n")
}
# Store samples after burn-in
if (iter > burn_in) {
samples$zeta0 <- c(samples$zeta0, zeta0)
samples$zeta1 <- c(samples$zeta1, zeta1)
samples$sigma2 <- c(samples$sigma2, sigma2)
samples$theta <- c(samples$theta, theta)
samples$gamma[, iter - burn_in] <- gamma
samples$eta[, iter - burn_in] <- eta  # Store eta
}
}
return(samples)
}
tensor.prod.model.matrix <- function(Bx, By) {
nx <- nrow(Bx)
ny <- nrow(By)
px <- ncol(Bx)
py <- ncol(By)
# 创建tensor product
B <- matrix(0, nx, px * py)
for (i in 1:px) {
for (j in 1:py) {
B[, (i-1)*py + j] <- Bx[,i] * By[,j]
}
}
return(B)
}
# Libraries
library(splines)
library(ggplot2)
library(GIGrvg)
library(fields)  # 用于二维可视化
set.seed(123)
n <- 10000  # 样本量
# Generate TWO dimensional spatial locations
coords_x <- runif(n, 0, 20)
coords_y <- runif(n, 0, 20)
# Define coefficients (two dimensional versions)
beta1 <- function(x, y) {
return(10 * sin(pi*x/15) * cos(pi*y/15))
}
beta2 <- function(x, y) {
return(5 * cos(pi*x/15) * sin(pi*y/15))
}
beta3 <- function(x, y) {
return(2 * sin(pi*(x-y)/8))
}
# Generate X matrix
X <- matrix(0, n, 10)  # 20个预测变量
for(j in 1:10) {
X[,j] <- rnorm(n)
}
# Generate y with noise
sigma <- 1 # 噪声水平
y <- numeric(n)
for(i in 1:n) {
y[i] <- beta1(coords_x[i], coords_y[i])*X[i,1] +
beta2(coords_x[i], coords_y[i])*X[i,2] +
beta3(coords_x[i], coords_y[i])*X[i,3] +
rnorm(1, 0, sigma)
}
# Visualize spatial effects
# 创建网格点用于可视化
grid_size <- 50
x_grid <- seq(0, 20, length.out = grid_size)
y_grid <- seq(0, 20, length.out = grid_size)
locations <- expand.grid(x = x_grid, y = y_grid)
# 计算每个系数在网格点上的值
beta1_grid <- matrix(beta1(locations$x, locations$y), grid_size, grid_size)
beta2_grid <- matrix(beta2(locations$x, locations$y), grid_size, grid_size)
beta3_grid <- matrix(beta3(locations$x, locations$y), grid_size, grid_size)
# 可视化
par(mfrow=c(1,3), mar=c(4,4,2,2))
# beta1的热图
image.plot(x_grid, y_grid, beta1_grid,
main="beta1(s)", xlab="x", ylab="y",
col=hcl.colors(50))
# beta2的热图
image.plot(x_grid, y_grid, beta2_grid,
main="beta2(s)", xlab="x", ylab="y",
col=hcl.colors(50))
# beta3的热图
image.plot(x_grid, y_grid, beta3_grid,
main="beta3(s)", xlab="x", ylab="y",
col=hcl.colors(50))
# 检查诊断信息
# 计算每个预测变量的实际贡献
contributions <- data.frame(
X1_effect = beta1(coords_x, coords_y) * X[,1],
X2_effect = beta2(coords_x, coords_y) * X[,2],
X3_effect = beta3(coords_x, coords_y) * X[,3]
)
# 打印效应的摘要统计
cat("\nEffect Size Summary:\n")
print(summary(contributions))
# 检查信噪比
signal <- beta1(coords_x, coords_y)*X[,1] +
beta2(coords_x, coords_y)*X[,2] +
beta3(coords_x, coords_y)*X[,3]
noise <- rnorm(n, 0, sigma)
SNR <- var(signal)/var(noise)
cat("\nSignal to Noise Ratio:", SNR, "\n")
# 相关性检查
cor_matrix <- cor(X[,1:3])
cat("\nCorrelation between active predictors:\n")
print(cor_matrix)
# 空间效应范围
cat("\nRange of spatial effects:\n")
cat("beta1:", range(beta1(coords_x, coords_y)), "\n")
cat("beta2:", range(beta2(coords_x, coords_y)), "\n")
cat("beta3:", range(beta3(coords_x, coords_y)), "\n")
n_basis_x <- 8
n_basis_y <- 8
# 运行二维空间变系数模型
samples <- spatial_full_2d(y = y,                    # 响应变量
X = X,                     # 预测变量矩阵
coords_x = coords_x,        # x坐标
coords_y = coords_y,        # y坐标
n_basis_x = n_basis_x,      # x方向的基函数数量
n_basis_y = n_basis_y,      # y方向的基函数数量
n_iter = 1000,              # MCMC迭代次数
burn_in = 200,             # burn-in期
a = 1, b = 10,              # theta的beta先验参数
a_sigma = 0.5,              # sigma2的逆伽马先验参数
b_sigma = 0.5,              # sigma2的逆伽马先验参数
lambda0 = 30,               # spike先验参数
lambda1 = 1,                # slab先验参数
zeta0 = 0.1,               # spike方差
zeta1 = 50)                # slab方差
posterior_gamma <- rowMeans(samples$gamma, na.rm = TRUE)
# Extract posterior mean of eta
posterior_eta <- rowMeans(samples$eta, na.rm = TRUE)
# 创建预测网格用于可视化
grid_size <- 50
x_seq <- seq(min(coords_x), max(coords_x), length = grid_size)
y_seq <- seq(min(coords_y), max(coords_y), length = grid_size)
pred_grid <- expand.grid(x = x_seq, y = y_seq)
# 重构beta函数并可视化
plot_reconstructed_beta <- function(eta_subset, n_basis_x, n_basis_y, pred_grid, title) {
Bx <- ns(pred_grid$x, df = n_basis_x)
By <- ns(pred_grid$y, df = n_basis_y)
B_pred <- tensor.prod.model.matrix(Bx, By)
beta_reconstructed <- matrix(B_pred %*% eta_subset, grid_size, grid_size)
image.plot(x_seq, y_seq, beta_reconstructed,
main = title,
xlab = "x", ylab = "y",
col = hcl.colors(50))
}
# 可视化每个beta
par(mfrow = c(2,3), mar = c(4,4,2,2))
# 真实的beta
for(i in 1:3) {
true_beta <- matrix(NA, grid_size, grid_size)
for(j in 1:grid_size) {
for(k in 1:grid_size) {
if(i == 1) true_beta[j,k] <- beta1(x_seq[j], y_seq[k])
if(i == 2) true_beta[j,k] <- beta2(x_seq[j], y_seq[k])
if(i == 3) true_beta[j,k] <- beta3(x_seq[j], y_seq[k])
}
}
image.plot(x_seq, y_seq, true_beta,
main = paste0("True beta", i),
xlab = "x", ylab = "y",
col = hcl.colors(50))
}
# 重构的beta
for(i in 1:3) {
start_idx <- (i-1) * (n_basis_x * n_basis_y) + 1
end_idx <- i * (n_basis_x * n_basis_y)
plot_reconstructed_beta(posterior_eta[start_idx:end_idx],
n_basis_x, n_basis_y, pred_grid,
paste0("Reconstructed beta", i))
}
for(i in 1:3) {
true_beta <- matrix(NA, grid_size, grid_size)
for(j in 1:grid_size) {
for(k in 1:grid_size) {
if(i == 1) true_beta[j,k] <- beta1(x_seq[j], y_seq[k])
if(i == 2) true_beta[j,k] <- beta2(x_seq[j], y_seq[k])
if(i == 3) true_beta[j,k] <- beta3(x_seq[j], y_seq[k])
}
}
image.plot(x_seq, y_seq, true_beta,
main = paste0("True beta", i),
xlab = "x", ylab = "y",
col = hcl.colors(50),
legend.lab = "Coefficient Value")  # 添加颜色条标签
}
data <- traindata
